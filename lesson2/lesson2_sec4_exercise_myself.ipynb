{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "lesson2_sec4_exercise_myself.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naomori/dl4us/blob/master/lesson2_sec4_exercise_myself.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzO_FYEPi-sJ",
        "colab_type": "text"
      },
      "source": [
        "# Lesson2 畳み込みニューラルネットワーク (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lJ8s0zHi-sK",
        "colab_type": "text"
      },
      "source": [
        "## 目次\n",
        "\n",
        "- Section1 解説\n",
        "  - 1.1 CNN基礎\n",
        "  - 1.2 Convolution(畳み込み)層\n",
        "  - 1.3 Pooling(プーリング)層\n",
        "  - 1.4 確認問題\n",
        "- Section2 実装①\n",
        "  - 2.1 Fasion MNISTをCNNでクラス分類\n",
        "  - 2.2 CIFAR10のデータをCNNでクラス分類\n",
        "- Section3 テクニック・発展内容\n",
        "  - 3.1 Data Augmentation\n",
        "  - 3.2 画像データの正規化\n",
        "  - 3.3 Batch Normalization\n",
        "  - 3.4 Skip Connection  (Residual Network)\n",
        "  - 3.5 学習済みネットワークの利用\n",
        "  - 3.6 学習させたモデルの保存・再利用\n",
        "  - 3.7 確認問題\n",
        "- Section4 実装②\n",
        "  - 4.1 CIFAR10のデータをCNNでクラス分類②\n",
        "- Section5 ケーススタディ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HCK-Hyli-sK",
        "colab_type": "text"
      },
      "source": [
        "## 3.7 の解答\n",
        "\n",
        "問1: ② 問2: ① 問3: ① 問4: ①"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4dDlY0ri-sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from IPython.display import SVG\n",
        "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "random_state = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1ohjqoGi-sN",
        "colab_type": "text"
      },
      "source": [
        "## Section4 実装②"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq33fK6Ji-sN",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 CIFAR10のデータをCNNでクラス分類②"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i93JYypqi-sO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "y_train = np.eye(10)[y_train.astype('int32').flatten()]\n",
        "\n",
        "x_test = x_test.astype('float32') / 255\n",
        "y_test = np.eye(10)[y_test.astype('int32').flatten()]\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train, y_train, test_size=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsZ9z29ji-sQ",
        "colab_type": "text"
      },
      "source": [
        "Section3の学習内容も踏まえて、CIFAR10のクラス分類を行いたいと思います。\n",
        "\n",
        "まず、モデルの作成を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIF6JNKCi-sQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "208a53c4-4a38-4507-d6cf-e1c670e14f08"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu',\n",
        "                 kernel_initializer='he_normal', input_shape=(32, 32, 3)))  # 32x32x3 -> 28x28x6\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  # 28x28x6 -> 14x14x6\n",
        "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
        "                 kernel_initializer='he_normal'))  # 14x14x6 -> 10x10x16\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  # 10x10x16 -> 5x5x16\n",
        "\n",
        "model.add(Flatten())  # 5x5x16 -> 400\n",
        "model.add(Dense(120, activation='relu',\n",
        "                kernel_initializer='he_normal'))  # 400 ->120\n",
        "model.add(Dense(84, activation='relu', kernel_initializer='he_normal'))  # 120 ->84\n",
        "model.add(Dense(10, activation='softmax'))  # 84 ->10\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.categorical_crossentropy,\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0829 04:14:20.868212 139923210962816 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxeFVzeui-sS",
        "colab_type": "text"
      },
      "source": [
        "次に、Section3で学習したDataAugumentationや画像データの正規化を学習に反映させてみます。\n",
        "\n",
        "kerasのImageDataGeneratorを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEMhk3FGi-sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    width_shift_range=0.2,  # 3.1.1 左右にずらす\n",
        "    height_shift_range=0.2,  # 3.1.2 上下にずらす\n",
        "    horizontal_flip=True,  # 3.1.3 左右反転\n",
        "    # 3.2.1 Global Contrast Normalization (GCN) (Falseに設定しているのでここでは使用していない)\n",
        "    samplewise_center=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False)  # 3.2.2 Zero-phase Component Analysis (ZCA) Whitening (Falseに設定しているのでここでは使用していない)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K2OCu3ti-sU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd54d4fc-9d07-4e56-b14f-e55b0dce0ee1"
      },
      "source": [
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n",
        "                    steps_per_epoch=x_train.shape[0] // 100, epochs=30, validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "400/400 [==============================] - 22s 55ms/step - loss: 1.9426 - acc: 0.2869 - val_loss: 1.7032 - val_acc: 0.3813\n",
            "Epoch 2/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.7028 - acc: 0.3789 - val_loss: 1.5774 - val_acc: 0.4277\n",
            "Epoch 3/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.6076 - acc: 0.4134 - val_loss: 1.5017 - val_acc: 0.4515\n",
            "Epoch 4/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.5557 - acc: 0.4392 - val_loss: 1.4281 - val_acc: 0.4841\n",
            "Epoch 5/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.4987 - acc: 0.4593 - val_loss: 1.3956 - val_acc: 0.4938\n",
            "Epoch 6/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.4616 - acc: 0.4740 - val_loss: 1.3705 - val_acc: 0.5041\n",
            "Epoch 7/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.4319 - acc: 0.4872 - val_loss: 1.3374 - val_acc: 0.5135\n",
            "Epoch 8/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.4057 - acc: 0.4942 - val_loss: 1.2936 - val_acc: 0.5282\n",
            "Epoch 9/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.3830 - acc: 0.5058 - val_loss: 1.2532 - val_acc: 0.5470\n",
            "Epoch 10/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.3607 - acc: 0.5098 - val_loss: 1.2355 - val_acc: 0.5556\n",
            "Epoch 11/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.3400 - acc: 0.5193 - val_loss: 1.2046 - val_acc: 0.5657\n",
            "Epoch 12/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.3252 - acc: 0.5249 - val_loss: 1.1806 - val_acc: 0.5768\n",
            "Epoch 13/30\n",
            "400/400 [==============================] - 19s 47ms/step - loss: 1.3142 - acc: 0.5316 - val_loss: 1.1849 - val_acc: 0.5705\n",
            "Epoch 14/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.2916 - acc: 0.5407 - val_loss: 1.2647 - val_acc: 0.5469\n",
            "Epoch 15/30\n",
            "400/400 [==============================] - 20s 49ms/step - loss: 1.2882 - acc: 0.5390 - val_loss: 1.1924 - val_acc: 0.5750\n",
            "Epoch 16/30\n",
            "400/400 [==============================] - 20s 49ms/step - loss: 1.2708 - acc: 0.5457 - val_loss: 1.2316 - val_acc: 0.5646\n",
            "Epoch 17/30\n",
            "400/400 [==============================] - 20s 49ms/step - loss: 1.2657 - acc: 0.5475 - val_loss: 1.1744 - val_acc: 0.5749\n",
            "Epoch 18/30\n",
            "400/400 [==============================] - 20s 49ms/step - loss: 1.2529 - acc: 0.5522 - val_loss: 1.1569 - val_acc: 0.5851\n",
            "Epoch 19/30\n",
            "400/400 [==============================] - 20s 49ms/step - loss: 1.2423 - acc: 0.5561 - val_loss: 1.1488 - val_acc: 0.5911\n",
            "Epoch 20/30\n",
            "400/400 [==============================] - 20s 50ms/step - loss: 1.2360 - acc: 0.5596 - val_loss: 1.2382 - val_acc: 0.5528\n",
            "Epoch 21/30\n",
            "400/400 [==============================] - 20s 49ms/step - loss: 1.2327 - acc: 0.5597 - val_loss: 1.1893 - val_acc: 0.5796\n",
            "Epoch 22/30\n",
            "400/400 [==============================] - 20s 49ms/step - loss: 1.2235 - acc: 0.5629 - val_loss: 1.1343 - val_acc: 0.5989\n",
            "Epoch 23/30\n",
            "400/400 [==============================] - 20s 50ms/step - loss: 1.2069 - acc: 0.5699 - val_loss: 1.1244 - val_acc: 0.6028\n",
            "Epoch 24/30\n",
            "400/400 [==============================] - 20s 49ms/step - loss: 1.2019 - acc: 0.5719 - val_loss: 1.1725 - val_acc: 0.5857\n",
            "Epoch 25/30\n",
            "400/400 [==============================] - 19s 49ms/step - loss: 1.1988 - acc: 0.5727 - val_loss: 1.1401 - val_acc: 0.5937\n",
            "Epoch 26/30\n",
            "400/400 [==============================] - 19s 49ms/step - loss: 1.1943 - acc: 0.5745 - val_loss: 1.1586 - val_acc: 0.5928\n",
            "Epoch 27/30\n",
            "400/400 [==============================] - 20s 49ms/step - loss: 1.1846 - acc: 0.5786 - val_loss: 1.0728 - val_acc: 0.6187\n",
            "Epoch 28/30\n",
            "400/400 [==============================] - 20s 49ms/step - loss: 1.1908 - acc: 0.5782 - val_loss: 1.1581 - val_acc: 0.5940\n",
            "Epoch 29/30\n",
            "400/400 [==============================] - 19s 49ms/step - loss: 1.1797 - acc: 0.5760 - val_loss: 1.2157 - val_acc: 0.5717\n",
            "Epoch 30/30\n",
            "400/400 [==============================] - 19s 48ms/step - loss: 1.1802 - acc: 0.5784 - val_loss: 1.1172 - val_acc: 0.6017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f420659da20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vswpNYCkle6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}